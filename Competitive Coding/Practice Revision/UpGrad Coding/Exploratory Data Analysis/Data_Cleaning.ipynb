{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [Bank Marketing Campaign EDA](https://colab.research.google.com/drive/19Xz8Ltdk0GqRwb2AusEt9MkuoyKWxPNe?usp=sharing)"
      ],
      "metadata": {
        "id": "ajqSrA3yThOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Type\n",
        "-----------\n",
        "\n",
        "Let's say there is a column in a dataset which essentially contains numerical values. \n",
        "\n",
        "But its data type is an object, which needs to be rectified and should be converted into int or float type.\n",
        "\n",
        "Choose the correct command to convert such object type column in a dataframe into integer or float type. \n",
        "\n",
        "More than one option may be correct.\n",
        "\n",
        "    df[\"feature\"]= df[\"feature\"].astype(int)\n",
        "\n",
        "    df.[\"feature\"]= df.[\"feature\"].astype(int)\n",
        "\n",
        "    df[\"feature\"]= df[\"feature\"].astype(float) \n",
        "\n",
        "    df.[\"feature\"]= df.[\"feature\"].astype(float)\n",
        "\n",
        "--------------\n",
        "\n",
        "    df[\"feature\"]= df[\"feature\"].astype(int)\n",
        "\n",
        "    df[\"feature\"]= df[\"feature\"].astype(float)\n",
        "\n",
        "    Feedback:\n",
        "    This particular command is used to convert any type of variable into float."
      ],
      "metadata": {
        "id": "Qnc55U9nSDDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Type\n",
        "-----------\n",
        "\n",
        "Find the average age of the customers in the bank marketing data set.\n",
        "\n",
        "    51\n",
        "\n",
        "    40\n",
        "\n",
        "    50\n",
        "\n",
        "    41\n",
        "\n",
        "-----------------\n",
        "\n",
        "`41` ✓ Correct\n",
        "\n",
        "    Feedback:\n",
        "\n",
        "Convert the age variable into numeric type from object type, which can be an integer, and then find the mean.\n",
        "\n",
        "    inp0[\"age\"]= inp0[\"age\"].astype(int)\n",
        "\n",
        "    inp0.age.mean()"
      ],
      "metadata": {
        "id": "nTsDJipETD7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLAs\n",
        "------\n",
        "\n",
        "In a database “MLA” containing the details of MLAs throughout India, you have a city named Rampur in Himachal Pradesh, UP and Chhattisgarh. \n",
        "\n",
        "The city names are stored in the “City” column, while state names are stored in the “State” column. \n",
        "\n",
        "What is the best way to represent the cities in this case?\n",
        "\n",
        "---------------------\n",
        "\n",
        "Keeping the most relevant Rampur, removing the other two\n",
        "\n",
        "    ✕ Incorrect\n",
        "      Feedback:\n",
        "\n",
        "    Removing the city name can lead to the loss of information.\n",
        "\n",
        "\n",
        "Merging the City, State columns to get a unique identifier\n",
        "\n",
        "    ✓ Correct\n",
        "      Feedback:\n",
        "\n",
        "    The city and state columns need to be merged so that each city is \n",
        "    uniquely identifiable for further analysis.\n",
        "\n",
        "\n",
        "Randomly choosing which Rampur to keep in the dataset, to make the dataset simpler"
      ],
      "metadata": {
        "id": "9oGJjvW6ViWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning of columns\n",
        "------------\n",
        "\n",
        "You have seen that Rahim has dropped the `“customerid”` column as it is of no use. \n",
        "\n",
        "For dropping the column, the command `inp0.drop(“customerid”, inplace= True)` has been used. \n",
        "\n",
        "Can you explain what the purpose of `inplace = True` in this code? \n",
        "\n",
        "Pick the correct option.\n",
        "\n",
        "--------------\n",
        "\n",
        "Use of inplace = True will return a new data frame without the 'customerid' column. It also drops the column in the original data frame, i.e., inp0.\n",
        "\n",
        "---------------\n",
        "\n",
        "Use of inplace = True only returns a new data frame without the 'customerid' column.\n",
        "\n",
        "---------------\n",
        "\n",
        "Use of `inplace = True does not return any new data frame` but is simply drops the customerid column in original data frame i.e. inp0.\n",
        "\n",
        "    ✓ Correct\n",
        "      Feedback:\n",
        "\n",
        "    When inplace = True is used, it performs the operation on dataframe \n",
        "    and nothing is returned.\n",
        "\n",
        "    When inplace = False is used, it performs the operation on \n",
        "    dataframe and returns a new copy of data.\n",
        "\n",
        "-------------------\n",
        "\n",
        "None of the above."
      ],
      "metadata": {
        "id": "Da_8ovCLYd3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning\n",
        "-----------\n",
        "\n",
        "What points should be kept in mind while handling the rows and columns for preparing the data for analysis and to fetch maximum information from it?\n",
        "\n",
        "------------\n",
        "\n",
        "Simply remove the columns if you find more than 20% of data in that column as missing. It may reduce the bulkiness of the data set and make it simple to analyse.\n",
        "\n",
        "-----------------\n",
        "\n",
        "Splitting a column into 2 or 3 columns increases the number of variables in the data set. However, one should remember that splitting is not preferred unless you get any unique information.\n",
        "\n",
        "    ✓ Correct\n",
        "      Feedback:\n",
        "\n",
        "    Columns should be split to get more variables if that yields any \n",
        "    unique and useful information. Like in our data set, \n",
        "    jobedu can be split into job and education.\n",
        "\n",
        "------------------\n",
        "\n",
        "In the bank marketing dataset, you can bucket the data according to age group, for example, <30, 30-40, 40-50, 50-60, >70, It may yield better insights about the responses based on age groups.\n",
        "\n",
        "    ✓ Correct\n",
        "      Feedback:\n",
        "\n",
        "    Bucketing by age group may yield new insights about the \n",
        "    perspective of different age groups.\n",
        "\n",
        "-----------------\n",
        "\n",
        "It is important to have information about the variables or instances, for example, whether they have null values, blank values or invalid values.\n",
        "\n",
        "    ✓ Correct\n",
        "      Feedback:\n",
        "\n",
        "    When you observe the dataset, it is necessary to look into \n",
        "    the count of null values. \n",
        "    You will learn more about it in further segments."
      ],
      "metadata": {
        "id": "9_GXRpB9fyoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Values\n",
        "--------\n",
        "\n",
        "Implement the code in your blank Jupyter notebook and find the exact number of missing values in the response column. \n",
        "\n",
        "Choose the correct option from the below.\n",
        "\n",
        "    30\n",
        "\n",
        "    40\n",
        "\n",
        "    50\n",
        "\n",
        "    60\n",
        "\n",
        "-----------\n",
        "\n",
        "`30` ✓ Correct\n",
        "\n",
        "    Feedback:\n",
        "\n",
        "The code in Python to find the missing values of the response column is as follows:\n",
        "\n",
        "    inp1.response.isnull().sum()"
      ],
      "metadata": {
        "id": "onM-BbR58egE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Values\n",
        "------------\n",
        "\n",
        "Implement the code in your blank Jupyter notebook and find the percentage of missing values in the response column. \n",
        "\n",
        "Choose the correct option from the below.\n",
        "\n",
        "    1%\n",
        "\n",
        "    0.1%\n",
        "\n",
        "    0.06%\n",
        "\n",
        "    0.006%\n",
        "\n",
        "-------------\n",
        "\n",
        "`0.06%` ✓ Correct\n",
        "\n",
        "    Feedback:\n",
        "\n",
        "You need to write the code in Python to find the missing values in the response column.\n",
        "\n",
        "    100 * (inp1.response.isnull().sum() / inp1.shape[0])"
      ],
      "metadata": {
        "id": "5oGL3pBb8_Ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Values\n",
        "-------\n",
        "\n",
        "What do you think about the treatment of missing values in the response column?\n",
        "\n",
        "----------------\n",
        "\n",
        "They should not be dropped, as that may affect the data set.\n",
        "\n",
        "    They can be removed because they are very small in number as \n",
        "    compared to entries in the dataset.\n",
        "\n",
        "    ✓ Correct\n",
        "      Feedback:\n",
        "\n",
        "    You can drop it as it is very less in percentage.\n",
        "    inp1 = inp1[~inp1.response.isnull()]\n",
        "\n",
        "Create a separate category named 'missing' to deal with such values."
      ],
      "metadata": {
        "id": "zQ9VMKOO9Wfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers\n",
        "---------\n",
        "\n",
        "Consider the following two statements:\n",
        "\n",
        "1. The difference between the maximum value of the balance variable and the 99th percentile is too high.\n",
        "\n",
        "2. The difference between the 99th percentile value and the 95th percentile value of the balance variable is in  the normal range, meaning it is not too high.\n",
        "\n",
        "Based on the above two statements, choose the correct option which concludes that the balance variable has outliers in it.\n",
        "\n",
        "\n",
        "    Statement 1 is alone sufficient to conclude that balance \n",
        "    variables have outliers.\n",
        "\n",
        "    Both the statements are insufficient to conclude that \n",
        "    the balance variable has outliers.\n",
        "\n",
        "    ✓ Both the statement are together sufficient to conclude \n",
        "    that it has outliers.\n",
        "\n",
        "    Any of the statement is alone sufficient to conclude \n",
        "    that the balance variable has outliers.\n",
        "\n",
        "-----------\n",
        "\n",
        "    Both the statement are together sufficient to conclude that it has outliers.\n",
        "\n",
        "    ✓ Correct\n",
        "      Feedback:\n",
        "\n",
        "Both the statements are simultaneously required for you to infer from statement 1 that if the maximum value of the variable is far from the 99th percentile, it gives a clear idea that there are outliers in the data set. \n",
        "\n",
        "In addition, from the 2nd statement, you can see that there is no huge difference between the quantile of 95th and 99th."
      ],
      "metadata": {
        "id": "SsmIOTdLKTds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers\n",
        "-----------\n",
        "\n",
        "Which of the following methods can be used to identify the outliers (univariate/multivariate) in the dataset?\n",
        "\n",
        "    Hint : More than one answer can be correct\n",
        "\n",
        "-------------\n",
        "\n",
        "Box plot can be used to plot the single variable and find its interquartile range and quantiles.\n",
        "\n",
        "    ✓ Correct\n",
        "      Feedback:\n",
        "\n",
        "    Box plot gives a clear picture of all the points and \n",
        "    visualises the quantiles to infer knowledge about the outliers.\n",
        "\n",
        "-------------------\n",
        "\n",
        "The difference of each point from the mean/median value in the dataset is alone sufficient to identify whether a point is an outlier or not.\n",
        "\n",
        "-------------\n",
        "\n",
        "Scatter plot can be used to identify the multivariate outliers.\n",
        "\n",
        "    ✓ Correct\n",
        "      Feedback:\n",
        "\n",
        "    Scatter plot between two variable gives the pictorial view of \n",
        "    multivariate outliers."
      ],
      "metadata": {
        "id": "KHF4tLk9LFXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers\n",
        "---------\n",
        "\n",
        "What is the mean and 75th percentile of the salary variable in bank marketing data set, respectively?\n",
        "\n",
        "    57004, 60000\n",
        "\n",
        "    57004, 70000\n",
        "\n",
        "    70000, 57004\n",
        "\n",
        "    60000, 57004\n",
        "\n",
        "-------------\n",
        "\n",
        "    57004, 70000\n",
        "\n",
        "    ✓ Correct\n",
        "      Feedback:\n",
        "\n",
        "Just write the following code to describe the salary variable. \n",
        "\n",
        "You will find the `mean` and `75th percentile`.  \n",
        "\n",
        "    inp1.salary.describe()\n",
        "\n",
        "-----------\n",
        "\n",
        "      count     45161.000000\n",
        "    ✓ mean      57004.849317\n",
        "      std       32087.698810\n",
        "      min           0.000000\n",
        "      25%       20000.000000\n",
        "      50%       60000.000000\n",
        "    ✓ 75%       70000.000000\n",
        "      max      120000.000000\n",
        "      Name: salary, dtype: float64"
      ],
      "metadata": {
        "id": "0ydjY6ajLkf6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lojDG0dtOmnD"
      },
      "outputs": [],
      "source": []
    }
  ]
}